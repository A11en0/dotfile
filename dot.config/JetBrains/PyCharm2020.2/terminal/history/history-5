java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
javac InsertSort.java 
java InsertSort
htop
sudo apt install htop
htop
cd
cd share/
ls
cd mnist
ls
cd ..
ls
cp mnist.npz ~/PycharmProjects/NLP/
ls
cp mnist ~/PycharmProjects/NLP/
cp -a mnist ~/PycharmProjects/NLP/
cd 
cd Documents/
ls
cd Thesis-read/
ls
cd org/
ls
cd 
cd Documents/
ls
cd Thesis-read/
ls
cd org/
ls
zathura lastweek.pdf 
ls
mv lastweek.pdf 葛宇航-汇报-2020-09-11.pdf
cd Code
ls
cd 
cd Code/
ls
cd Java/
ls
cd ..
lsc
ls
cd Screencast/
ls
cd src/
ls
cd com/
ls
cd company/
ls
cd
ls
cd -
ls
javac Receiver.java 
java Receiver
ls
javac SendScreen.java 
ls
cp SendScreen.java Receiver.java ~/
cd
ls
mkdir screen
mv *.java screen/
cd screen/
ls
javac SendScreen.java 
vi SendScreen
vi SendScreen.java 
ls
javac SendScreen
javac SendScreen.java 
javac SendScreen.java -Xlint:deprecation
javac SendScreen.java 
java SendScreen
ls
javac SendScreen
javac SendScreen.java 
ls
javac Receiver.java 
java Receiver
ls
vi Receiver.
vi Receiver.java 
ls
java Receiver
java Receiver.java 
vi Receiver.java 
javac Receiver.java 
java Receiver
java SendScreen
vi SendScreen
vi SendScreen.java 
ls
vi Receiver.java 
javac Receiver.java 
java Receiver
javac Receiver.java 
java Receiver
javac Receiver.java 
cd
rg
ls
ip a
vi .condarc 
conda activate nlp2
pip install ipykernel
conda list
conda install ipykernel
python -m ipykernel install --user --name your_env_name --display-name your_env_name 
python -m ipykernel install --user --name nlp2 --display-name nlp2
python
python -m ipykernel install --user --name nlp2 --display-name nlp2
sudo apt install python-backports.functools-lru-cache
python -m ipykernel install --user --name nlp2 --display-name nlp2
sudo apt install python-backports.functools-lru-cache
sudo apt upgrade
python -m ipykernel install --user --name nlp2 --display-name nlp2
pip uninstall backports.functools_lru_cache
pip install backports.functools_lru_cache
python -m ipykernel install --user --name nlp2 --display-name nlp2
jupyter-notebook 
pip install torch==1.6.0+cu92 torchvision==0.7.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html
conda install pytorch torchvision cudatoolkit=9.2 -c pytorch
jupyter-notebook 
conda install numpy matplotlib
jupyter-notebook 
conda install numpy pandas
jupyter-notebook 
conda list
conda list | grep torch
conda install pytorch torchvision cudatoolkit=9.2 -c pytorch
conda list | grep torch
jupyter-notebook 
nmtui
dhclient -k
sudo dhclient -k
sudo dhclient -r
ip a
jupyter-notebook 
ls
sudo apt install neofetch
neofetch 
ls
rg
ls
vi seafile-server-7.1-ubuntu-amd64-http 
cd /etc/nginx/
ls
cd sites-available/
ls
vi seafile.conf 
ls
sudo rm -rf seafile.conf 
cd ..
ls
cd sites-enabled/
ls
sudo rm -rf seafile.conf 
ls
cd 
ls
./
cd Downloads/
ls
cd ..
ls
cd Downloads/
ls
./hplip-3.20.6.run 
pip search python3-pyqt4
./hplip-3.20.6.run 
pip search python3-pyqt4
pip install python3-pyqt4
pip search python3-pyqt4
sudo aptitude search python3-pyqt4
sudo apt install python3-pyqt4
sudo apt install python3-dbus
./hplip-3.20.6.run 
sudo apt search python3-pyqt4
sudo aptitude search python3-pyqt4
sudo apt search python3-pyqt4
sudo apt search python3-dbus
ls
sudo dhclient -r
sudo dhclient -k
sudo dhclient 
sudo dhclient -k
sudo dhclient -s
sudo dhclient -r
ip a
ping 8.8.8.8
sudo dhclient
ping 8.8.8.8
nmtui
ls
nmtui
ip a
nmtui
dhclient
dhclient -r
sudo dhclient 
ping 8.8.8.8
ip a
cd /usr/share/ppd/
ls
cd hplip/
ls
cd HP/
ls
sudo rm -rf *
ls
cd
cd Code/
ls
git clone https://github.com/andreafrancia/trash-cli.git
cd trash-cli
sudo python setup.py install
trash-list 
ls
cd 
ls
mkdir 第二周工作报告
mv lastweek.tex 第二周工作报告.tex
mv lastweek.org 第二周工作报告.org
mv lastweek.pdf 第二周工作报告.pdf
ls
mv 葛宇航-汇报-2020-09-11.pdf 第二周工作报告.pdf
ls
mv 第二周工作报告* 第二周工作报告
ls
mv *.png 第二周工作报告/
ls
qiv exp3.jpg 
mv exp3.jpg 第二周工作报告/
ls
vi Distributed\ Representations\ of\ Sentences\ and\ Documents.org 
ls
rm -rf lastweek.bbl 
ls
cd
cd gtd/
ls
rg
cd 
cd .config/ranger/
ls
vi scope.sh 
ls
vi rc.conf 
cd 
cd .config/ranger/
ls
vi rc.conf 
adb shell
ls
cd
adb shell
ls
wps 20190625-计算机科学与技术-学术型硕士研究生培养方案.docx 
cd
wget http://127.0.0.1/lib/f5d90316-2e1f-4fea-b93f-9b50cfad72a0/file/20160952004-%E8%91%9B%E5%AE%87%E8%88%AA-%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%99%BA%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2-%E9%9D%A2%E5%90%91%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%BB%E9%A2%98%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0.pdf?dl=1
ls
rg
wget http://127.0.0.1/lib/f5d90316-2e1f-4fea-b93f-9b50cfad72a0/file/20160952004-%E8%91%9B%E5%AE%87%E8%88%AA-%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%99%BA%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2-%E9%9D%A2%E5%90%91%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%BB%E9%A2%98%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%AE%9E%E7%8E%B0.pdf?dl=1
ip a
emacs
killall v2ray
v2ray &
ls
cd 
cd /opt/seafile/
ls
mv seafile-server-7.0.5/ seafile-server-latest
cd seafile-server-latest/
ls
cd ..
ls
cd seafile-server-latest
ls
cd
cd -
ls'
ls
cd
cd flarum/
pwd
vi .nginx.conf
pwd
vi .nginx.conf
ls
cd Documents/
ls
cd Thesis-read/
ls
cd pdf/
ls
cd Reading/
ls
zathura BERT\:\ Pre-training\ of\ Deep\ Bidirectional\ Transformers\ forLanguage\ Understanding.pdf 
rg
cd
cd /etc/nginx/conf.d/
ls
cd ..
ls
cd sites-available/
ls
sudo su
cd
sudo vi /usr/share/nginx/html/
sudo cd /usr/share/nginx/html/
cd /usr/share/nginx/html/
ls
vi phpinfo.php
sudo vi phpinfo.php
service nginx restart
sudo service nginx restart
ls
sudo service nginx restart
ls
vi index.html 
pwd
ls
sudo chown -R www-data /usr/share/nginx/html
cd 
cd /etc/nginx/conf.d/
ls
vi default.conf 
sudo vi default.conf 
sudo service nginx restart
ls
vi default.conf 
sudo vi default.conf 
sudo service nginx restart
journalctl -xe
sudo journalctl -xe
!
ls
vi default.conf 
sudo service nginx restart
journalctl -xe
sudo journalctl -xe
ls
sudo journalctl -xe
ls
vi default.conf 
ls
vi default.conf 
sudo vi default.conf 
ls
cp default.conf ~/
sudo vi default.conf 
sudo service nginx restart
sudo vi default.conf 
sudo service nginx restart
sudo vi default.conf 
sudo service nginx restart
sudo vi default.conf 
sudo service nginx restart
sudo vi default.conf 
sudo service nginx restart
cd 
cd -
ls
vi default.conf 
sudo vi default.conf 
sudo service nginx restart
sudo vi default.conf 
sudo service nginx restart
sudo vi default.conf 
nginx t
nginx -t
sudo nginx -t
sudo nginx -s reload
sudo vi default.conf 
ls
rm -rf default.conf 
sudo rm -rf default.conf 
cp ~/default.conf .
sudo cp ~/default.conf .
vi default.conf 
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
ls
sudo nginx -s reload
sudo service nginx restart
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
ls
vi default.conf 
sudo vi default.conf 
vi default.conf 
sudo nginx -s reload
vi default.conf 
sudo vi default.conf 
sudo nginx -s reload
sudo service nginx restart
sudo vi default.conf 
sudo nginx -s reload
sudo service nginx restart
ls
sudo rm -rf default.conf 
cp ~/default.conf .
sudo cp ~/default.conf .
sudo nginx -s reload
vi default.conf 
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo service nginx restart
sudo vi default.conf 
sudo service nginx restart
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
sudo service nginx restart
sudo nginx -s reload
sudo vi default.conf 
sudo nginx -s reload
sudo service nginx restart
sudo vi default.conf 
sudo service nginx restart
sudo vi default.conf 
sudo nginx -s reload
sudo service nginx restart
sudo nginx -s reload
nginx -t
sudo nginx -t
ls
cp ~/flarum.conf .
sudo cp ~/flarum.conf .
sudo service nginx restart
nginx -t
sudo nginx -t
ls
vi flarum.conf 
sudo vi flarum.conf 
sudo service nginx restart
sudo vi flarum.conf 
sudo service nginx restart
sudo nginx -s reload
sudo sudo nginx -s reload
sudo nginx -s reload
vi flarum.conf 
ls /usr/share/nginx/flarum/public/
vi flarum.conf 
sudo vi flarum.conf 
sudo nginx -s reload
sudo vi flarum.conf 
ls
vi default.conf 
sudo vi flarum.conf 
sudo nginx -s reload
sudo vi flarum.conf 
sudo nginx -s reload
sudo vi flarum.conf 
sudo nginx -s reload
sudo vi flarum.conf 
sudo nginx -s reload
sudo vi flarum.conf 
sudo nginx -s reload
mysql -uroot -p
cd /etc/php/7.4/
ls
cd fpm/p
cd fpm/
ls
systemctl status php7.4-fpm nginx
cd /opt/seafile/
l
ls
cd ccnet/
ls
cd ccnet/
ls
cd seafile-server-7.0.5/
ls
cd seafile
ls
cd ..
ls
sudo su
cd
cd /opt/seafile/seafile-server-latest
ls
cd ..
ls
cd conf/
sudo su
cd
php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"
sudo aptitude search php
sudo sudo aptitude search php
sudo apt-get install php5-common libapache2-mod-php5 php5-cli
sudo apt -y install lsb-release apt-transport-https ca-certificates 
sudo wget -O /etc/apt/trusted.gpg.d/php.gpg https://packages.sury.org/php/apt.gpg
echo "deb https://packages.sury.org/php/ $(lsb_release -sc) main" | sudo tee /etc/apt/sources.list.d/php.list
sudo apt update
sudo apt -y install php7.4
sudo systemctl disable --now apache2
sudo apt-get install nginx php7.4-fpm
php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"
php -r "if (hash_file('sha384', 'composer-setup.php') === '795f976fe0ebd8b75f26a6dd68f78fd3453ce79f32ecb33e7fd087d39bfeb978342fb73ac986cd4f54edd0dc902601dc') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;"
php composer-setup.php
php -r "unlink('composer-setup.php');"
composer create-project flarum/flarum . --stability=beta
upt'; unlink('composer-setup.php'); } echo PHP_EOL;"
php composer-setup.php
php -r "if (hash_file('sha384', 'composer-setup.php') === '795f976fe0ebd8b75f26a6dd68f78fd3453ce79f32ecb33e7fd087d39bfeb978342fb73ac986cd4f54edd0dc902601dc') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;"
php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"
php -r "if (hash_file('sha384', 'composer-setup.php') === '795f976fe0ebd8b75f26a6dd68f78fd3453ce79f32ecb33e7fd087d39bfeb978342fb73ac986cd4f54edd0dc902601dc') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;"
php composer-setup.php
mv composer.phar /usr/local/bin/composer
sudo mv composer.phar /usr/local/bin/composer
composer create-project flarum/flarum . --stability=beta
mkdir flarum
cd flarum/
composer create-project flarum/flarum . --stability=beta
nmtui
ls
rg
ls
cd ..
cd flarum/
ls
tree
vi .nginx.conf 
cd
dict granularity
dict holistically
dict holistical
dict holistic
dict objective
rg
sudo apt install nmap
nmap
nmap -V 127.0.0.1
nmap -v 127.0.0.1
man nmap
nmap -sS -O scanme.nmap.org/24
nmap -sS -O 127.0.0.1/24
sudo nmap -sS -O 127.0.0.1/24
source .bashrc
ls
rg
LS
cd 
cd Code/
ls
proxychains git clone https://github.com/alison-carrera/onn.git
ip a
cd /usr/local/
ls
nvcc --version
nvidia-smi 
cuda
whereis cuda
cat /usr/lib/cuda/version.txt 
cat /usr/lib/cuda/include/
cd /usr/lib/cuda/include/
ls
cd ..
ls
cd bin/
ls
cd ..
cd nvvm/
ls
cd 
cd /usr/lib/cuda/
ls
cd bin/
ls
ls -la
sudo su
cd
mv .pip/ share/
cp -a share/.pip/ .
pip uninstall tensorflow-gpu
pip install tensorflow-gpu==1.10.0
ls
conda activate nlp
conda install onn
pip install onn
cd Code/python/
ls
python onn.py 
pip install onn
python onn.py 
mv o
mv onn.py onn_warmup.py 
python onn_warmup.py 
vi onn_warmup.py 
python onn_warmup.py 
vi onn_warmup.py 
python onn_warmup.py 
vi onn_warmup.py 
python onn_warmup.py 
pip install joblib
pwd
cd 
rg
jupyter-notebook 
jupyter notebook --generate-config
vi .jupyter/jupyter_notebook_config.py 
jupyter-notebook 
jupyter-notebook echo "c.NotebookApp.ip = '0.0.0.0'" >> ~/.jupyter/jupyter_notebook_config.py
echo "c.NotebookApp.ip = '0.0.0.0'" >> ~/.jupyter/jupyter_notebook_config.py
jupyter-notebook 
nmtui
ls
mv Downloads/higgs.npz ~/Code/
jupyter-notebook 
cd Code/
ls
jupyter-notebook 
ls
cp -a MRPC/ BERT-Classification-Tutorial/
cp -a BERT-Classification-Tutorial/ ~/share/
docker ps
docker ps -a
docker images
sudo nvidia-docker run -it -p 7777:8888 --ipc=host -v /home/shcd/Documents/gby:/gby --name gby-notebook  90be7604e476
docker images
sudo nvidia-docker run -it -p 7777:8888 --ipc=host -v /home/allen/share:/data --name tensorflow1.x-notebook cf60a305ba7b
ls
cd Downloads/
ls
cd
conda activate nlp
cd Code/
ls
cd BERT-Classification-Tutorial/
ls
cd ..
ls
python bert_tutorial.py 
cd datasets/
ls
unrar x SST-2.rar 
proxychains git clone https://gitee.com/Finch1/FuckDailyCP.gitH
proxychains git clone https://gitee.com/Finch1/FuckDailyCP.git
cd FuckDailyCP/
ls
pip install -r requirements.txt 
python3 DailyCP.py 
vi DailyCP.py 
ls
cd doc/
ls
cd ..
ls
cd formdb/
ls
cd ..
ls
python3 DailyCP.py 
python3 DailyCP.py 合肥工业大学 2020111071 086632 安徽省合肥市 ./formdb/
cd ..
cd
rg
ip a
conda activate nlp
torch.cuda.is_available()
python
cd Code/
ls
cd B
cd Bert-TextClassification/
ls
cd ..
sudo wget -O /etc/apt/trusted.gpg.d/php.gpg https://packages.sury.org/php/apt.gpg
jupyter-notebook 
pip install tensorboardX
python3 run_SST2.py --max_seq_length=65 --num_train_epochs=5.0 --do_train --gpu_ids="1" --gradient_accumulation_steps=8 --print_step=100  # train and test
python3 run_SST2.py --max_seq_length=65 --num_train_epochs=5.0 --do_train --gpu_ids="1" --gradient_accumulation_steps=8 --print_step=100  
python3 run_SST2.py --max_seq_length=65   # test
python3 run_SST2.py --max_seq_length=65 --num_train_epochs=5.0 --do_train --gpu_ids="1" --gradient_accumulation_steps=8 --print_step=100  # train and test
python3 run_SST2.py --max_seq_length=65 --num_train_epochs=5.0 --do_train --gpu_ids="1" --gradient_accumulation_steps=8 --print_step=100  
pip freeze | grep torch
python
python3 run_SST2.py --max_seq_length=65 --num_train_epochs=5.0 --do_train --gpu_ids="1" --gradient_accumulation_steps=8 --print_step=100  
nvidia-smi 
kill -9 6668
kill -9 6466
nvidia-smi 
python3 run_SST2.py --max_seq_length=65 --num_train_epochs=5.0 --do_train --gpu_ids="1" --gradient_accumulation_steps=8 --print_step=100  
P
nmtui
conda activate nlp
conda install pytorch torchvision cudatoolkit=9.2 -c pytorch
python
conda install pytorch torchvision cudatoolkit=9.2 -c pytorch
nvcc _v
nvcc -V
whereis cuda
cd /usr/lib/cuda/
ls
cd bin/
ls
cd 
cd /usr/include/
ls
cd 
cd /usr/lib/cuda/
ls
rg
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-ubuntu1604.pin
cd
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-ubuntu1604.pin
sudo mv cuda-ubuntu1604.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
proxychains wget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
cd /usr/local/cuda
whereis cuda
sudo apt list | grep cuda
sud apt-get remove --auto-remove nvidia-cuda-toolkit
sudo apt-get remove --auto-remove nvidia-cuda-toolkit
sudo apt-get remove nvidia-cuda-toolkit
sudo apt-get remove --auto-remove nvidia-cuda-toolkit
whereis cuda
sudo dpkg -i cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
nvcc 
nvcc -v
nvcc -V
ls /usr/local/ | grep cuda
nvidia-smi 
sudo apt list | grep cud
sudo apt remove nvidia-cuda-dev/stable
sudo dpkg -i cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
sudo dpkg -i --force-overwrite cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
sudo mv cuda-ubuntu1604.pin /etc/apt/preferences.d/cuda-repository-pin-600
sudo dpkg -i cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
`sudo dpkg -i cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64.deb`
ls
4
sudo dpkg -i cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
sudo apt install -f
sudo dpkg -i cuda-repo-ubuntu1604-11-0-local_11.0.3-450.51.06-1_amd64.deb
rg
wget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda_11.0.3_450.51.06_linux.run
proxychains wget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda_11.0.3_450.51.06_linux.run
ls
chmod +x cuda_11.0.3_450.51.06_linux.run 
./cuda_11.0.3_450.51.06_linux.run 
sudo ./cuda_11.0.3_450.51.06_linux.run 
d
cd 
ls
emacs
cd Code/
ls
cd BERT-Classification-Tutorial/
ls
nmtui
CD
cd 
cd Code/
ls
cd python/
ls
cd results/
ls
cd ..
ls
cd Demo/
ls
cd ..
ls
rg
cd
rg
cd
cd Code/
ls
conda activate nlp
jupyter-notebook 
cd ..
ls
cd share/
jupyter-notebook 
pip freeze | grep tensor
pip freeze 
pip install tensorflow==1.10.0
pip freeze | grep tensor
python3 run_SST2.py --max_seq_length=65 --num_train_epochs=5.0 --do_train --gpu_ids="1" --gradient_accumulation_steps=8 --print_step=100  
pip uninstall tensorflow-gpu
pip freeze | grep tensor
pip uninstall tensorflowboard
pip uninstall tensorboard
pip freeze | grep tensor
pip uninstall tensorboardX
pip freeze | grep tensor
pip install tensorflow==1.10
cd
rg
cd share/
ls
proxychains git clone https://github.com/ToneLi/KASM-Short-text-classification.git
cd
cd Code/python/
ls
conda activate nlp
cd tensorflow_tutor/
ls
python day1.py 
jupyter-notebook 
ip a
cd 
cd .ssh/
ls
vi id_rsa.pub 
ls
cd 
ls
docker -ps -a
docker -a -ps 
docker -ps 
docker -a ps 
docker ps -a 
docker start cf60a305ba7b
docker start 83bf5965a089
docker start 808a2349ccff'
docker start 808a2349ccff
docker attatch 808a2349ccff
docker atatch 808a2349ccff
docker attatch 808a2349ccff
docker attach 808a2349ccff
cd
ls
ip a
rg
cd /media/allen/KINGSTON/
ls
cd Code/
ls
proxychains git clone https://github.com/graykode/nlp-tutorial.git
proxychains git clone https://github.com/Socialbird-AILab/BERT-Classification-Tutorial.git
conda activate nlp
cd BERT-Classification-Tutorial/
ls
python download_glue.py --
rg
mkdir glue_data
python download_glue.py --data_dir glue_data --tasks all
proxychains python download_glue.py --data_dir glue_data --tasks all
vi download_glue.py 
ls
proxychains python download_glue.py --data_dir glue_data --tasks all
ls
cd ..
ls
mkdir MRPC
ls
sudo aptitude search cabextract
sudo apt install cabextract
cabextract MSRParaphraseCorpus.msi -d MRPC
ls
cd MRPC/
ls
cat MRPC/_2DEC3DBE877E4DB192D17C0256E90F1D | tr -d $'\r' > MRPC/msr_paraphrase_train.txt
cd ..
cat MRPC/_2DEC3DBE877E4DB192D17C0256E90F1D | tr -d $'\r' > MRPC/msr_paraphrase_train.txt
cat MRPC/_D7B391F9EAFF4B1B8BCE8F21B20B1B61 | tr -d $'\r' > MRPC/msr_paraphrase_test.txt
rm MRPC/_*
rm -rf MRPC/_*
ls
cd MRPC/
ls
cd ..
ls
cd BERT-Classification-Tutorial/
ls
rm -rf .#download_glue.py 
ls
python run_classifier.py 
pip install tensorflow==1.9.2
pip install --ignore-installed --upgrade tensorflow_gpu==1.8.0
nvcc -V
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
cat /usr/local/cuda/version.txt
python
python run_classifier.py 
pip uninstall tensorflow
pip uninstall tensorflow-gpu
pip install tensorflow-gpu==1.9.0
python run_classifier.py 
cd
vi .bashrc
nvcc -V
ls
rg
docker attach 83bf5965a089
docker start 83bf5965a089
docker attach 83bf5965a089
ps -a 
docker ps -a 
docker start 808a2349ccff
docker attach 808a2349ccff
cd Downloads/
ls
unzip ScienceDirect_articles_13Sep2020_08-42-44.290.zip 
ls
rg
ls
qiv ai-top-conferences.jpg 
ls
rg
ls
cd 
cp CentOS-6.5-x86_64-bin-DVD1.iso /media/allen/KINGSTON/
cd
ls
cd Downloads/
ls
rg
vi /etc/nginx/conf.d/default.conf 
vi /etc/nginx/sites-available/seafile.conf 
cd 
cd Downloads/
ls
gzip -d GoogleNews-vectors-negative300.bin.gz 
ls
mv GoogleNews-vectors-negative300.bin ~/Code/python/
ls
cd
ls
ping 192.168.56.4
ping 192.168.56.101
scp hadoop-3.1.1.tar.gz allen@192.168.56.101
scp hadoop-3.1.1.tar.gz allen@192.168.56.101:~/
rg
cd 
ls
rg
ls
rg
ls
cd Downloads/
ls
scp jdk-8u212-linux-x64.tar.gz allen@192.168.56.101:~/
ip a
hpot
htop
ls
cd 
rg
cd Downloads/
ls
cd ..
rg
ls
ping 192.168.56.100
ls
cd mnist/
ls
cd MNIST/
ls
cd ..
ls
cp *.gz ~/Code/python/tensorflow代码/
ls
j
ls
cd ..
ls
cd tensorflow代码/
ls
cp Basis.ipynb ../tensorflow_tutor/
trash Basis.ipynb 
mv feature_selection.ipynb ../tensorflow_tutor/
mv data-03-diabetes.csv ../tensorflow_tutor/
mv MNIST_data/ ../tensorflow_tutor/
cp ../tensorflow_tutor/MNIST_data/* data/
cd 
cd Code/python/
ls
unrar x tweets-original.rar 
ls
rg
lls
ls
unzip text8.zip 
ls
vi text8
ls
mv GoogleNews-vectors-negative300.bin tweets-original
cd 
rg
nvidia-smi 
kill -9 21972
nvidia-smi 
conda activate nlp
python
pip freeze | grep torch
java 
javac
javac -v
javac -V
javac --version
javac -version
java -version
javac -version
java -version
ip a
sudo apt install ssh-server
sudo apt install ssh
ping master
ping 192.168.1.100
ping 192.168.56.100
cd Code/
ls
cd python/
ls
cd ..
ls
mv bert_tutorial.py ~/PycharmProjects/pythonProject/
proxychains git clone https://github.com/songyingxin/Bert-TextClassification.git
conda activate nlp
jupyter-notebook 
cd
cd share/
jupyter-notebook 
ls
jupyter-notebook 
ls
cd ..
ls
cd Code/
ls
cd python/
ls
cd tensorflow代码/
ls
jupyter-notebook 
LS
cd ..j
cd ..
jupyter-notebook 
ls
scp hadoop-3.1.1.tar.gz 192.168.56.100:~
ls
scp hadoop-3.1.1.tar.gz 192.168.56.100:~
ls
cp SST-2.rar ~/Code/python/
cd ~/Code/python/
ls
unrar x SST-2.rar 
ls
cd SST-2
ls
pwd
ls
cd
conda activate nlp
pip install ipywidgets
jupyter nbextension enable --py widgetsnbextension
pip install pip install ipywidgets
conda install -c conda-forge ipywidgets
jupyter nbextension enable --py widgetsnbextension
pip freeze | grep ipywidgets
python
pip install --upgrade jupyter_client 
conda install -n py36 -c conda-forge ipywidgets
cd Documents/
ls
zathura Array\ programming\ with\ NumPy.pdf 
ls
cd Thesis-read/
ls
cd org/
ls
rg
CD 
cd 
cd Documents/
ls
cd Thesis-read/
ls
cd pdf/
ls
rg
ls
cd ..
ls
cd ..
ls
cd ..
ls
rg
ls
cd Code/
ls
cd 
cd share/
ls
cd
nmtui
ls
rg
ls
cd ..
ls
mv mnist ~/Code/python/
cd ~/Code/python/
ls
cd mnist/
ls
cd MNIST/
ls
cd processed/
ls
cd ..
ls
cd raw/
ls
cd ..
ls
cd 
cd Code/
cd python/
ls
cd mnist/
ls
cd ..
ls
cp -a mnist/ ~/PycharmProjects/pythonProject/
c
nvcc -V
pwd
cd 
nmtui
cd Documents/
ls
rg
cd
rg
rg
ls
rg
ping 192.168.56.100
ls
cd Downloads/
ls
cd
cd /media/allen/KINGSTON/
ls
cp -a 1111/ ~
ls
cd
ls
cd 1111/
ls
unzip 安徽2018大数据竞赛资料.zip 
ls
unzip 完整培训资料.zip 
ls
unzip 安徽省2017年大数据竞赛培训资料.zip 
ls
rar x 
ls
cd
cd
ssh 192.168.56.100
cd
ssh 192.168.56.100
ssh 192.168.56.101
ls
ssh 192.168.56.101
ls
ssh 192.168.56.101
ssh 192.168.56.100
ssh 192.168.56.101
ssh 192.168.56.100
ssh 192.168.56.101
ping 192.168.1.4
ping 192.168.56.101
sudo vi /etc/hosts
ping master
ls
scp r master:/home/allen/hadoop/share/hadoop/common .
scp -r master:/home/allen/hadoop/share/hadoop/common .
ls
cd h
cd hadoop
ls
cd ..
cd Code/
ls
cd 
ls
ssh master
ls
cd common/
ls
cd 
cd
ls
scp -r master:/home/allen/hadoop/share/hadoop/hdfs .
ls
mv hdfs/ hadoop
mv common/ hadoop
ls
cd
ls
ls /
cd 
cd Downloads/
ls
scp hbase-1.1.2-bin.tar.gz master:~/
ls
cd
cd hadoop
ls
scp master:~/hbase-jar .
scp -r master:~/hbase-jar .
telnet 192.168.1.4 8020
telnet master 8020
cd
latexmk resume.tex 
ls
mkdir resume
mv resume.* resume
cd resume/
ls
xelatex --escape-shape resume.tex 
xelatex --escape-shell resume.tex 
xelatex resume.tex 
ls
vi resume.tex 
xelatex resume.tex 
vi resume.tex 
xelatex resume.tex 
cd WanHuCV/
ls
xelatex WanHu-CV-EN.tex 
zathura  WanHu-CV-EN.pdf 
ls
xelatex WanHu-CV-EN.tex 
nmtui
killall xelatex
proxychains git clone https://github.com/huwan/WanHuCV.git
ls
ping master
ssh master
}
ls
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 哈哈哈
python sample.py   --converter_path model/novel/converter.pkl   --checkpoint_path  model/novel   --use_embedding   --max_length 2000   --num_layers 3   --lstm_size 256   --embedding_size 256
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 你
ls
rg
nmtui
cd
cd /media/allen/03FB-416B/
ls
cd 
cd -
ls
pwd
nmtui
ping 8.8.8.8
ip a
pdw
pwd
ls
cd
ls
unzip 论文论文.zip 
ls
rg
q
cd
hp-setup 
zathura Documents/Thesis-read/pdf/Reading/Short\ Text\ Classification\ via\ Knowledge\ powered\ Attention\ withSimilarity\ Matrix\ based\ CNN.pdf 
zathura Documents/Thesis-read/pdf/Reading/ijcai2017.pdf 
hp-setup 
man hp-setup 
hp-setup 
ls
rg
ls
python run.sh 
./run.sh
chmod +x run.sh 
./run.sh 
ls
cd ..
ls
cd tweets-original
ls
cd 
conda actiave nlp
fuck
fuck2
conda activate nlp
conda install numpy
conda uninstall numpy
conda install numpy
python -m ipykernel install --user --name 环境名称 --display-name "在jupyter中显示的环境名称"
python -m ipykernel install --user --name bert --display-name "bert"
conda activate bert
conda list
jupyter kernelspec remove 环境名称
jupyter kernelspec remove bert
jupyter
cd PycharmProjects/
ls
tree
ls
rg
ls
cd NLP/
ls
cd ..
ls
git clone git clone https://github.com/google-research/bert.git
git clone https://github.com/google-research/bert.git
proxychains git clone https://github.com/google-research/bert.git
cd
rg
ls
cd PycharmProjects/
ls
cd bert/
ls
vi run.sh 
ls
mkdir data
vi run.sh 
ls
cd data/
ls
cd ..
ls
mkdir bert
ls
pwd
cd
rg
cd 
cd Downloads/
ls
cp -a uncased_L-12_H-768_A-12.zip ~/PycharmProjects/bert/
cd ~/PycharmProjects/
ls
cd bert/
ls
mv uncased_L-12_H-768_A-12.zip bert/
cd bert/
s
ls
unzip uncased_L-12_H-768_A-12.zip 
ls
cd uncased_L-12_H-768_A-12
ls
cd ..
ls
cd ..
ls
cd data/
ls
unzip stanfordSentimentTreebank.zip 
ls
cd stanfordSentimentTreebank
ls
vi sentiment_labels.txt 
vi STree.txt 
vi datasetSplit.txt 
ls
cd ..
pwdj
pwd
cd 
cd Code/python/
ls
conda activate nlp
jupyter-notebook 
conda install jupyter-notebook
conda install jupyter
jupyter-notebook 
jupyter kernelspec remove 环境名称
jupyter kernelspec remove bert
python -m ipykernel install --user --name bert --display-name bert
jupyter-notebook 
ls
jupyter-notebook 
pip install jupyter
jupyter-notebook 
ls
rg
pip list | grep tensor
./run.sh 
wwww
pip install --upgrade numpy
./run.sh 
pip uninstall numpy
conda install numpy
pip install --upgrade numpy
conda install numpy
./run.sh 
conda uninstall tensorflow
conda install tensorflow==1.11.0
./run.sh 
conda create -n "bert" python==3.6
conda activate bert
conda install numpy
conda install -r requirements.txt 
conda install requirements.txt 
conda -r install requirements.txt 
conda install tensorflow==1.4.0
conda install tensorflow==1.11.0
./run.sh 
mv bert/ model
./run.sh 
mkdir output
./run.sh 
pip install numpy
pip list
pip install tensorflow 1.10.0
pip install tensorflow==1.10.0
pip install tensorflow==1.13.1
pip list
ls
cd 4_SST2/
ls
cd 1_self_entity/
ls
python train.py 
pip install tensorflow==1.3.1
pip install tensorflow==1.13.1
python train.py 
pip install tensorflow==1.13.1
python train.py 
ls
ls
rg
ls
mkdir NLP
mv Bert-TextClassification/ NLP
mv BERT-Classification-Tutorial/ NLP
ls
rg
cd python/
ls
mkdir Datasets
rg
cd
ls
rg
ping master
vi /etc/hosts
sudo vi /etc/hosts
ls
rg
ls
unzip KASM.zip 
pwd
conda list
conda install tensorflow==1.13.1
conda actiavte bert
conda activate bert
conda install tensorflow==1.13.1
pip uninstall pandas
pip install pandas
conda install python==3.7
pip install pandas
conda uninstall pandas
conda install pandas
cd 
cd -
ls
proxychains git clone https://github.com/MemorialCheng/JD_NLP.git
cd JD_NLP/
ls
rg
ls
cd videos/
ls
cd 
cd
rg
cd Downloads/
ls
unzip Tutorial.zip 
ls
cd
rg
conda activate tc
conda activate -n tc python==3.6
conda activate -n tc python==3.7
conda activate -n "tc" python==3.7
conda activate -n tc python==3.7
conda create -n tc python==3.7
conda activate tc
jupyter-notebook 
conda install 
conda activate bert
conda uninstall numpy
conda list
conda install numpy
cd .anaconda3/envs/nlp/lib/python3.6/
ls
cd site-packages/
ls
rm -rf numpy*\
rm -rf numpy*
cd 
conda install numpy
pip install numpy
conda activate tc
ls
pip install pandas
conda install pandas
conda activate bert
conda install pandas
python\
python
ls
conda install pandas
python
pip install pandas
pyth0on
python
pip install scikit-learn
pip install pytorch
pip install torch
rg
cd 
cd Code/hadoop_example/
ls
cd out/artifacts/hadoop_example_jar/
ls
cp hadoop_example.jar ~
cd 
scp wordcount.jar master:~
scp hadoop_example.jar master:~
ls
ls -ls
ls -la
ls -l
ls -l hadoop*
ls -lh hadoop*
du -d 0
du -d 1
du -d 0
du -d 1
du -dh 1
du -h 1
du -h -d 1
ls
cd Downloads/
ls
scp apache-hive-0.13.1-bin.tar.gz master
rm -rf master 
scp apache-hive-0.13.1-bin.tar.gz master:~
ls
cd 
cd Downloads/
ls
cd 
ls
cd Downloads/
ls
cd scala/
ls
scp mysql-connector-java-5.1.27.tar.gz master:~
ls
mv mysql-connector-java-5.1.27.tar.gz ../
cd
cd 
cd Downloads/
ls
scp hive-data.rar master:~
cd 
cd Downloads/
ls
unrar x hive-data.rar 
zip -r hive-data hive-data.zip 
zip -r hive-data.zip hive-data
cd 
cd Downloads/
ls
scp hive-data.zip master:~
ls
cd 
cd Downloads/
ls
mkdir python可视化 
ls
mv Seaborn数据可视化分析.pptx python可视化/
ls
vi .config/i3/config
ssh master
ls
rg
cd 
cd Downloads/
ls
scp fastjson-1.2.31.jar hadoop2lib.tar.gz master:~
ls
./idea.sh 
cd
cd Downloads/
ls
mkdir qingxi
mv hadoop2lib.tar.gz fastjson-1.2.31.jar qingxi/
rg
ls
rg
ls
cd 
rg
Time taken: 12.846 seconds
cd .local/share/
ls
cd Kingsoft/
ls
cd office6
ls
cd oleobject/
ls
vi Ole_1601296968260658_320349440.log 
cd 
cd Downloads/
ls
cd qingxi/
ls
vi log.txt 
ls
cp log.txt ~/Code/qingxi/
cd 
ls
cd 
cd /media/allen/
ls
cd 03FB-416B/
ls
cd 18-19-2-大数据教学资源/
ls
tree
cd ..
ls
cd 
ls
rg
ls
cd 
cd Downloads/qingxi/
ls
vi log.txt 
ls
scp Downloads/qingxi/log.txt master:~
ls
cd Dow
cd Downloads/
ls
rg
uptime
ls
vi Downloads/qingxi/log.txt 
cal
ls
rg
scp Downloads/Python-3.6.8.tgz master:~
ls
tail -10 log_movie.txt 
scp log_movie.txt master:~
cd Downloads/
ls
scp spark-2.4.7-bin-hadoop2.6.tgz master:~
ssh 
ls
vi README.md 
conda activate bert
tensorboard --logdir=./logs/
ls
cd
ls
cd Downloads/
ls
zathura A\ Review\ of\ Feature\ Selection\ and\ Its\ Methods.pdf 
ls
vi
ls
cd ..
vi 
ssh 
ls
vi README.md 
pwd
vi README.md 
python sample.py \                                                                                                                                                        
vi README.md 
python sample.py --converter_path model/jay/converter.pkl \                                                                                                               
python sample.py --converter_path model/jay/converter.pkl 
ls
cat README.md 
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay  \                            
ip a
ls
cat README.md 
pwd
>python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 哈哈哈
ls
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 哈哈哈
conda activate bert
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我知道
conda activate nlp
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我知道
conda envs 
conda list envs 
conda envs list
conda env 
conda env  list
conda env list
conda activate tc
conda list 
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我知道
conda activate bert
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我知道
pip3 install IPython
e
python -m pip install --upgrade pip
pip3 install IPython
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我知道
i  p
i       p
i           p
i              p
i                 p
i                    p 
i                       p 
i                          p 
i                             p 
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我知道
ls
rg
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我知道
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我爱你
ls
python craw.py 
pip install urllib2
pip install urllib
pip install requests
python craw.py 
pip install requests
python craw.py 
ls
vi data.txt 
rm -rf data.txt 
python craw.py 
vi data.txt 
echo "" > data.txt 
vi data.txt 
python craw.py 
vi data.txt 
python craw.py 
vi data.txt 
python craw.py 
vi data.txt 
python craw.py 
ls
mv data.txt data
cd data/
ls
cd ..
python train.py    --input_file data/jay.txt   --num_steps 20   --batch_size 32   --name jay   --max_steps 5000   --learning_rate 0.01   --num_layers 3 \
python train.py    --input_file data/jay.txt   --num_steps 20   --batch_size 32   --name jay   --max_steps 5000   --learning_rate 0.01   --num_layers 3 --use_embedding
python train.py --input_file data/data.txt   --num_steps 20   --batch_size 32   --name jay   --max_steps 5000   --learning_rate 0.01   --num_layers 3 --use_embedding
python train.py --input_file data/data.txt   --num_steps 20   --batch_size 32   --name qinghua   --max_steps 5000   --learning_rate 0.01   --num_layers 3 --use_embedding
python sample.py --converter_path model/jay/converter.pkl   --checkpoint_path  model/jay    --max_length 500    --use_embedding   --num_layers 3   --start_string 我知道
ls
ls model
ls model/qinghua/
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 50    --use_embedding   --num_layers 3   --start_string 不
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 50    --use_embedding   --num_layers 10   --start_string 不
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 50    --use_embedding   --num_layers 3   --start_string 我
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 50    --use_embedding   --num_layers 3   --start_string 我爱你
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 50    --use_embedding   --num_layers 3   --start_string 我爱
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 30    --use_embedding   --num_layers 3   --start_string 我爱
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 30    --use_embedding   --num_layers 3   --start_string 我爱你
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 30    --use_embedding   --num_layers 3   --start_string 我
python sample.py --converter_path model/qinghua/converter.pkl   --checkpoint_path  model/qinghua    --max_length 10    --use_embedding   --num_layers 3   --start_string 我
vi data/data.txt 
ls
vi README.md 
ls
python train.py --input_file data/data.txt   --num_steps 20   --batch_size 32   --name qinghua   --max_steps 5000   --learning_rate 0.01   --num_layers 3 --use_embedding
dict neglect
ls
rg
nmtui
cd
nmtui
ip a
nmtui
ls
dhclient -r
dhclient 
sudo dhclient 
sudo dhclient -r
ip a
nmtui
ip a
nmtui
ip a
sudo dhclient -r
sudo dhclient -k
sudo dhclient 
ip a
sudo dhclient 
sudo dhclient -r
sudo dhclient 
ip a
ping 8.8.8.8
nmtui
ip a
ping 8.8.8.8
ip a
nmtui
sudo dhclient 
ip a
nmtui
ip a
sudo dhclient 
sudo dhclient -r
sudo dhclient 
ip a
ping 8.8.8.8
ip a
cd Downloads/
ls
cd 
rg
rg
ls
cd Dow
cd Downloads/
ls
pwd
ls
pwd
cd ..
ls
cd Downloads/
ls
cd qingxi/
ls
tar zxvf hadoop2lib.tar.gz 
ls
cd
rg
cd Downloads/
ls
unrar x 大数据竞赛.rar 
rg
cd
rg
vim /etc/hosts
pip install pytorch
pip install torch torchvision
pkill pdftex
pkill latex
unzip thesis.zip 
cd thesis
ls
cd
cd Documents/tikz/
ls
pdftex periodic.tex 
ls
pdftex nn_big.tex 
pdftex nn.tex 
rg
cd
rg
texdoc -l lshort
ls
rg
pdflatex plane_partion.tex 
pdflatex Turing\ machine.tex 
pdflatex flowchart.tex 
nvcc -v
nvcc -version
nvcc --version
conda activate bert
conda install pytorch torchvision cudatoolkit=10.1 -c pytorch
cd Documents/tikz/
ls
pdflatex nn.tex 
ls
rg
pdflatex nn1.tex 
rg
pdflatex nn2.tex 
rg
pdflatex nn3.tex 
rg
pdflatex nn3.tex 
rg
pdflatex framework.tex 
rg
pdflatex bayes.tex 
rg
pdflatex hypersurface.tex 
pdflatex heatmap.tex 
rg
pdflatex 
pdflatex nn_big.
pdflatex nn_big.tex 
pdflatex periodic.tex 
rg
pdflatex periodic.tex 
rg
pdflatex periodic.tex 
rg
pdflatex rooty_helix.tex 
rg
pdflatex swan_wave_model.tex 
rg
pdflatex plane.tex 
rg
pip list
conda install torchtext
pip install torchtext
pip install scikit-learn
pip install tagme
